{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "A = np.array([3.06, 500, 6])\n",
    "B = np.array([2.68, 320, 4])\n",
    "C = np.array([2.92, 640, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_vector(v, f):\n",
    "    if v.shape != f.shape:\n",
    "        return v\n",
    "    return v * f\n",
    "\n",
    "def get_cos_dist(v1, v2):\n",
    "    dist = v1.dot(v2) / np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102422.90926642582\n",
      "409642.61873518024\n",
      "409639.5506017164\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "\n",
    "factors = np.array([1, 1, 1])\n",
    "\n",
    "scaledA = scale_vector(A, factors)\n",
    "scaledB = scale_vector(B, factors)\n",
    "scaledC = scale_vector(C, factors)\n",
    "\n",
    "get_cos_dist(scaledA, scaledB)\n",
    "get_cos_dist(scaledA, scaledC)\n",
    "get_cos_dist(scaledB, scaledC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.22705985718422\n",
      "57.99246564438056\n",
      "56.68372761689134\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "\n",
    "factors = np.array([1, 0.01, 0.5])\n",
    "\n",
    "scaledA = scale_vector(A, factors)\n",
    "scaledB = scale_vector(B, factors)\n",
    "scaledC = scale_vector(C, factors)\n",
    "\n",
    "get_cos_dist(scaledA, scaledB)\n",
    "get_cos_dist(scaledA, scaledC)\n",
    "get_cos_dist(scaledB, scaledC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.63627862320873\n",
      "34.543804248192586\n",
      "34.54370554019432\n"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "\n",
    "factors = np.array([1 / np.mean(A), 1 / np.mean(B), 1 / np.mean(C)])\n",
    "\n",
    "scaledA = scale_vector(A, factors)\n",
    "scaledB = scale_vector(B, factors)\n",
    "scaledC = scale_vector(C, factors)\n",
    "\n",
    "get_cos_dist(scaledA, scaledB)\n",
    "get_cos_dist(scaledA, scaledC)\n",
    "get_cos_dist(scaledB, scaledC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "### How can a competitor - in principle - try to steal the valuable data for recommendations on this website?\n",
    "\n",
    "The attacker could create fake accounts which like certain items where the competitor does not have much data about. The given recommendations can be then collected and possibly exploited.\n",
    "\n",
    "### Does this work better when the web shop implemented a content-based or a collaborative filtering system?\n",
    "\n",
    "Content-based systems are problematic for attackers, as they are not based on other user data. So the recommdations are only based on attackers input, which is not useful. Collaborative filtering systems (user-user) is preferred as their recommendations are based on other users' ratings.\n",
    "\n",
    "### What data would the competitor be able to infer?\n",
    "\n",
    "The competitor cannot infer any further data from the recommendations. He cannot infer which features the similar products share aswell as the ratings by the similar users. The whole similarity matrix is unknown.\n",
    "\n",
    "### Would this technique have an impact on the recommendation system, i.e. would this attack create a bias on the data?\n",
    "\n",
    "Only for Collaborative Filtering (user-user) an attack would create a bias on the data. This requires the attacker to create enough accounts with enough ratings. The reason for that is that the recommender system evaluates all similar users, which could be fake accounts.\n",
    "\n",
    "### Why is this attack probably not viable in any case?\n",
    "\n",
    "An attacker does not gain any insight into the user or item data. He will solely be presented with recommendations, which even might be biased and thus not representative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "### a) We store the artistid aliases as a dictionary, as it is reasonably small. This makes it efficient to update the utility matrix with the correct artist ids.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('lab2').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1059637| 1000010|      238|\n",
      "|1059637| 1000049|        1|\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49481"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origSchema = StructType([\n",
    "    StructField('userid', IntegerType(), True),\n",
    "    StructField('artistid', IntegerType(), True),\n",
    "    StructField('playcount', IntegerType(), True)\n",
    "])\n",
    "\n",
    "origDF = spark.read.option('delimiter', ' ').schema(origSchema).csv('user_artist_data_small.txt')\n",
    "origDF.show(2)\n",
    "origDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliasDict = {}\n",
    "with open('artist_alias_small.txt') as f:\n",
    "    for line in f:\n",
    "        (key, val) = line.split()\n",
    "        aliasDict[int(key)] = int(val)\n",
    "\n",
    "\n",
    "def get_alias(key):\n",
    "    ret = key\n",
    "    if key in aliasDict.keys():\n",
    "        ret = aliasDict[key]\n",
    "    return ret\n",
    "\n",
    "get_alias_udf = F.udf(get_alias, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1059637| 1000010|      238|\n",
      "|1059637| 1000049|        1|\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correctedDF = origDF.withColumn(\n",
    "    'artistid',\n",
    "    get_alias_udf(origDF['artistid'])\n",
    ")\n",
    "\n",
    "correctedDF.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(playcount)=1878.5849582172702)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allArtistsDF = correctedDF.select('artistid').distinct().sort(correctedDF.artistid.asc())\n",
    "test = correctedDF.where(correctedDF.userid == 1059637).sort(correctedDF.artistid.asc())\n",
    "test.select(avg(test.playcount)).collect()\n",
    "#test.join(allArtistsDF, test.artistid == allArtistsDF.artistid, 'right').drop('userid').drop('artistid').withColumn('playcount', F.when(F.col('playcount').isNull(), 0).otherwise(F.col('playcount'))).show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(userid1, userid2, alldf, artistsdf):\n",
    "    def get_r(userid):\n",
    "        r = alldf.where(df['userid'] == userid)\n",
    "        avg = r.select(avg(r['playcount'])).collect()\n",
    "        # Normalize r by subtracting average\n",
    "        r = r.select(r['playcount'] - avg)\n",
    "        # Format r, such that all artist ids are included\n",
    "        r = r.sort(alldf['artistid'].asc()) \\\n",
    "            .join(artistsdf, alldf['artistid'] == artistsdf['artistid'], 'right') \\\n",
    "            .drop('userid') \\\n",
    "            .drop('artistid') \\\n",
    "            .withColumn(\n",
    "                'playcount',\n",
    "                F.when(\n",
    "                    F.col('playcount').isNull(), 0\n",
    "                ).otherwise(F.col('playcount'))\n",
    "            )\n",
    "        return r\n",
    "            \n",
    "    r1 = get_r(userid1)\n",
    "    r2 = get_r(userid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
